\chapter{Теоретико-аналитическая часть}

  \section{Постановка задачи}

    Исследовать возможность использования семантико-синтаксического
    анализатора Compreno в качестве источника высокоуровневых признаков для задачи
    NER на корпусе CoNLL 2003 в рамках нейросетевого подхода.

  \section{Обзор литературы}

    Победители соревнования по NER CoNLL 2003 \citep{florian2003named}, получившие 88.76\% F1,
    представили систему использующую комбинацию различных алгоритмов машинного обучения.
    В качестве признаков был использован их собственный, вручную составленный газетир,
    POS-теги, CHUNK-теги, суффиксы, префиксы и выход других NER-классификаторов,
    тренированных на внешних данных.

    \citep{collobert2011natural} представили комбинацию сверточной нейронной сети
    с условными случайными полями, получившую 89.59\% F1 на корпусе CoNLL 2003.
    Их нейросетевая архитектура не зависит от задачи и используется как для NER, так и для
    частеречной разметки (part-of-speech tagging), поиска синтаксически связанных групп
    соседних слов (chunking), установления семантических ролей (semantic role labelling).
    Для задачи NER они использовали три типа признаков - векторное представление слова,
    капитализацию и небольшой газетир, включенный в соревнование CoNLL 2003.

    \citep{chiu2015named} представили комбинацию сверточных сетей, рекуррентных сетей
    и условных случайных полей показывающую 91.62\% F1.
    Они использовали такие же признаки как у \citep{collobert2011natural}, дополнительный, вручную сформированный
    газетир на основе DBpedia и обучались на
    train+dev\footnote{Объединенная обучающая и валидационная выборки} выборке CoNLL 2003.
    Кроме корпуса CoNLL 2003 они тестировали архитектуру
    на более крупном англоязычном корпусе OntoNotes 5.0. На нем они получили
    state-of-the-art результат 86.28\%.

    \citep{DBLP:journals/corr/YangSC16} представили глубокую иерархическую рекуррентную нейросетевую
    архитектуру с условными случайными полями для разметки последовательностей.
    Они использовали такие же признаки как у \citep{collobert2011natural}.
    Кроме англоязычного корпуса CoNLL 2003, где они получили state-of-the-art 90.94\% F1 при обучении
    только на обучающей выборке (train set), они тестировали работу нейросети на CoNLL 2002 Dutch NER и CoNLL 2003 Spanish NER.
    На этих корпусах они улучшили предыдущий state-of-the-art результат:
    82.82\% до 85.19\% на CoNLL 2002 Dutch NER и 85.75\% до 85.77\% на CoNLL 2003 Spanish NER.

    Современные работы используют векторное представление слов
    и условные случайные поля в своих моделях. Из сторонних признаков применяют
    только газетиры. В работах \citep{xu2014rc, bian2014knowledge} описано применение дополнительных признаков для
    слов (морфологических, синтаксических, семантических) для создания более
    совершенных векторных представлений.
    Такие векторные представления помогают повысить оценку качества в
    прикладных задачах \citep{xu2014rc}.

  \section{Обзор корпусов для задачи NER}

  \subsection{Схемы разметки корпуса}

  \section{Обзор нейросетевого подхода к решению задачи NER}

  В этом разделе будет рассмотрен подход на основе сверточной нейронной сети из работы
  \citep{collobert2011natural}. Была выбрана именно эта работа т.к:
  \begin{itemize}
  \item в ней представлена модель, получающая сравнимую со state-of-the-art F1-меру на CoNLL 2003,
  \item представленная модель имеет различные программные имплементации,
  \item векторные представления слов под названием <<Senna Embeddings>>
    используемые в этой работе находятся в открытом доступе в сети.
  \end{itemize}
  Последние два пункта указывают на возможность воспроизведения результатов из статьи относительно небольшими усилиями.

  Традиционным подходом к решению задач из области автоматической обработки текстов,
  включая NER, является использованием алгоритма обучения с учителем, например
  машины опорных векторов с линейным ядром. Вручную составленные признаки подаются на вход
  алгоритма обучения с учителем. Выбор признаков - это практически полностью эмпирический
  процесс, построенный на лингвистической интуиции и решаемой задаче.

  Нейросетевой подход предполагает использование минимального количества признаков.
  Обычно это векторные представления слов полученные из большого корпуса с использованием
  алгоритмов обучения без учителя.

  % Векторные представления слов

  Согласно Википедии\footnote{\url{https://en.wikipedia.org/wiki/Word_embedding}},
  \textit{векторное представление} — это общее название для различных
  подходов к моделированию языка и обучению представлений в обработке естественного языка,
  направленных на сопоставление словам (и, возможно, фразам) из некоторого словаря
  векторов из $R^n$, где $n$ - значительно меньше количества слов в словаре (обычно от 50 до 1000).

  \citep{collobert2011natural} использовали нейронные сети для построения векторных представлений слов.
  Они тренировали нейронную сеть на данных корпусе английской
  Википедии\footnote{На данных ноября 2007 года из http://download.wikimedia.org}
  и Reuters RCV1\footnote{Доступно http://trec.nist.gov/data/reuters/reuters.html}.
  Были использованы 130000 самых частотных слов, остальные слова кодировались
  специальным токеном UNKNOWN.
  Полученные векторные представления называются Senna Embeddings и доступны в сети
  по адресу: http://ronan.collobert.com/senna/.

  Senna Embeddings использовались как входные признаки на нейронные сети для решения задачи NER.
  В работе \citep{collobert2011natural} описываются две нейросетевые модели:
  \begin{itemize}
  \item Оконный (window), который предсказывает тег слова на основе контекста (окна) вокруг слова,
  \item сверточный (convolution), который предсказывает тег слова используя всё предложение.
  \end{itemize}

  Оконная модель представлена на рис. \ref{figure:window_net}.
  \begin{figure}[h]
    \centering
    \caption{Оконная модель из \citep{collobert2011natural}}
    \includegraphics{figures/window.png}
    \label{figure:window_net}
  \end{figure}

  На рис. \ref{figure:window_net} предсказывается тег для слова on.
  При классификации используется контекст для этого слова.
  Всё окно состоящее из 5 слов пропускается через так называемый Lookup Table.

  \textit{Lookup Table} - это специальной слой в нейронной сети, который
  отображает каждое слово в вектор весов. Причем вектор весов обучается вместе с сетью.
  Более формально, каждому слову $w$ из словаря $D$ ставится в соответствие
  вектор размерности $d$, который задается Lookup Table слоем $LT_W(w)$:
  \[
    LT_W(w) = W_{\cdot,w},
  \]
  где $W \in R^{d\times|D|}$ - матрица весов для обучения, $W_{\cdot,w}$ - $w$-ый столбец
  матрицы $W$.

  Также этот слой может принимать на вход последовательность слов $w_1 \ldots w_K$.
  В этом случае выходом будет матрица:
  \[
    LT_W(w_1 \ldots w_K) = ( W_{\cdot, w_1} \ldots W_{\cdot, w_K})
  \]

  После Lookup Table слоя, полученная матрица преобразуется в один вектор с
  помощью операции Concat:
  \[
    f_{1} = Concat(LT_W(w_1 \ldots w_K)) =
      \begin{bmatrix}
        W_{\cdot, w_1} \\
        \vdots \\
        W_{\cdot, w_K}
      \end{bmatrix},
  \]


    \subsection{Выбор метода решения задачи}

      Лучший результат для задачи NER на CoNLL 2003 показывает комбинация нейросети и
      условных случайных полей. Они довольно сложны в реализации с нуля, т.к. не поддерживаются
      существующими фреймворками.

      Условные случайные поля сами по себе показывают неплохой
      результат, но долго обучаются и требуют сложную инженерию признаков.

      Нейронные сети показывают достаточно хороший результат, быстро обучаются,
      расширяемы и
      имеют различные Open Source библиотеки, поддерживаемые сообществом и крупными
      компаниями.
      Исходя из цели работы был выбран нейросетевой подход. В перспективе в него
      можно внедрить условные случайные поля для получения state-of-the-art результата.

  \section{Синтактико-семантические признаки}
    Существует много инструментов для получения дополнительных признаков для слова.
    Для извлечения синтаксических признаков часто используют MaltParser \citep{nivre2006maltparser}.
    Для получения семантических признаков применяют BabelNet \citep{navigli2010babelnet}.

    В данной работе для получения синтактико-семантических признаков используется Compreno.
    Вершины синтактико-семантического дерева Compreno кодировались бинарным представлением
    и соотносились с токенами исходного
    текста\footnote{Почти для всех токенов в соответствующем дереве нашлась соответствующая вершина.
    Токены для которых не была найдена вершина, кодировались специальным признаком 83951},
    тем самым наделяя их синтактико-се\-ман\-ти\-ческими признаками.
    Размерность пространства синтактико-се\-ман\-ти\-ческих признаков получилась равной 83950.

    Плотные вектора большой размерности сильно замедляют процесс оптимизации и для хорошего
    обучения требуется много данных и вычислительных ресурсов.
    В таких случаях часто применяют методы для уменьшения размерности,
    например сингулярное разложение или автоэнкодеры. Минусом таких методов является потеря информации
    после сжатия.

    Если же вектора большой размерности разреженные, то используют специальные методы для
    работы с такими данными \citep{davissurvey}.

    В данной работе предлагается 2 способа внедрения синтактико-семантических признаков:
    \begin{itemize}
      \item сжать синтактико-семантические вектора с помощью сингулярного разложения (SVD) и добавить
      как еще один Lookup Table в сверточную нейронную сеть;
      \item добавить еще одну нейронную сеть для синтактико-семантических признаков и оптимизировать
      её вместе со сверточной нейронной сетью.
    \end{itemize}
