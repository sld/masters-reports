\chapter{Проектная часть}
\section{Алгоритмизация выбранного метода решения задачи }

  Для реализации была выбрана сверточная нейронная сеть из статьи \citep{collobert2011natural}.
  Из модели были удалены условные случайные поля для более быстрого обучения и проведения экспериментов.

  В качестве признаков выступают вектора слов, позиция относительно слова в предложении
  для которого предсказывается тег, капитализация и присутствие слова в газетире,
  который включен в соревнование CoNLL 2003.

  Общий алгоритм работы следующий:
  \begin{enumerate}
    \item В начало и конец предложения добавляют по одному специальному токену, чтобы его длина была
    не меньше трех. Каждый токен отображается в набор идентификаторов признаков.
    На вход нейросети поступает набор идентификаторов признаков для всего предложения.

    \item Набор идентификаторов пропускается через специальный слой (lookup table), который отображает
    каждый идентификатор в вектор весов. На выходе каждому токену предложения соответствует
    вектор.
    \item Полученные вектора объединяются в матрицу признаков предложения.
    \item Полученная матрица признаков подается на следующий
    слой, который проходится окном размера 3 и выполняет операцию свертки (temporal convolution).
    Т.е. три столбца матрицы признаков конкатенируются в один вектор и перемножаются
    на матрицу весов справа.
    На выходе получается матрица с количеством строк фиксированной длины (для любого предложения).
    \item Затем извлекается максимум по каждой строке (max over time).
    Таким образом все предложения любой длины получают вектор признаков фиксированной длины.
    \item Полученный вектор признаков подается на полносвязный слой.
    \item Затем выход полносвязного слоя подается на выходной слой, который возвращает вероятность
    для каждого тега (softmax).
  \end{enumerate}

  В качестве функции потерь используется кросс-энтропия (cross entropy).

  Подробная математическая модель описана в статье \citep{collobert2011natural}.

\section{Программная часть}

\subsection{Выбор программного фреймворка}


\subsection{Реализованная модель}

Нейронная сеть написана с использованием открытого фреймворка torch\footnote{http://torch.ch}.

Код для воспроизведения экспериментов выложен по адресу:
\href{https://github.com/sld/torch-conv-ner}{github.com/sld/torch-conv-ner}.

Скорость обучения на машине с GPU Amazon AWS g2.2xlarge\footnote{https://aws.amazon.com/ru/ec2/instance-types/}:
\begin{itemize}
\item 1 эпоха при одиночной обработке (stochastic gradient descent): $\sim$450 сек.
\item 1 эпоха при пакетной обработке (mini-batch gradient descent): $\sim$171 сек.
\item Модель получающая 87.49\% обучалась 91 эпоху ($\sim$4.2 часа).
\item 1 эпоха при пакетной обработке с использованием признаков Compreno: $\sim$615 сек.
\end{itemize}

Скорость классификации составляет 2500 токенов в секунду при пакетной обработке.

