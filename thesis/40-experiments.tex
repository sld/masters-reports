\chapter{Экспериментальная часть}


\section{Эксперименты без синтактико-семантических признаков}
По таблице \ref{table:raw_net} видно, что результаты немного ниже чем у \citep{collobert2011natural}.
Это связано с тем, что для Window подхода использован другой метод оптимизации,
а для Convolution подхода не были применены условные случайные поля (ConvNet + CRF в таблице \ref{table:raw_net}).

В качестве референсной, будет использована модель из последнего эксперимента
показывающая 87.49\% F1.
Это сделано для чистоты эксперимента, т.к. далее  обучение происходило только
на обучающей выборке по правилам соревнования CoNLL 2003 и применялся mini-batch
gradient descent для ускорения экспериментов.

\newpage

\begin{table}[!h]
  \caption{Результаты экспериментов без использования синтактико-семантических признаков}
  \centering
  \begin{tabulary}{\textwidth}{| L | L | L | L | L | L |}
    \hline\hline
    \multicolumn{1}{|p{1.7cm}|}{Модель} & Признаки & Выборка & Метод оптимизации & Полученная F1, \% & F1 в статье \cite{collobert2011natural} \\
    \hline
    Window & Embeddings, Capitalization & train & Mini-batch gradient descent & 86.27 & - \\
    \hline
    Window & Embeddings, Capitalization & train & Stochastic gradient descent & - & 86.97 \\
    \hline
    ConvNet + CRF & Embeddings, Capitalization, Position & train & Stochastic gradient descent & - & 88.67 \\
    \hline
    ConvNet + CRF & Embeddings, Capitalization, Position, Gazetteer & train & Stochastic gradient descent & - & 89.59 \\
    \hline
    ConvNet & Embeddings, Capitalization, Position & train & Stochastic gradient descent & 86.77 & - \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer & train & Stochastic gradient descent & 87.89 & - \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer & train + dev & Stochastic gradient descent & 88.37 & - \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer & train & Mini-batch gradient descent & \textbf{87.49} & - \\
    \hline
  \end{tabulary}
  \label{table:raw_net}
\end{table}

\section{Эксперименты с синтактико-семантическими признаками сжатыми с использованием SVD}

\begin{table}[!h]
  \caption{Результаты с синтактико-семантическими признаками сжатыми SVD}
  \centering
  \begin{tabulary}{\textwidth}{| L | L | L | L | L | L |}
    \hline\hline
    \multicolumn{1}{|p{1.7cm}|}{Модель} & Признаки & Выборка & Метод оптимизации & Полученная F1, \% \\
    \hline
    ConvNet & Position, Compreno SVD 1024 & train & Mini-batch gradient descent & 75.89 \\
    \hline
    ConvNet & Capitalization, Position, Gazetteer, Compreno SVD 1024 & train & Mini-batch gradient descent & 81.83 \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer, Compreno SVD 1024 & train & Mini-batch gradient descent & 86.85 \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer & train & Mini-batch gradient descent & 87.49 \\
    \hline
  \end{tabulary}
  \label{table:svd_net}
\end{table}


По таблице \ref{table:svd_net} видно, что такой способ ведет к небольшому ухудшению F1-меры.


\section{Эксперименты с синтактико-семантическими признаками для совместно-оптимизированной нейросети}

Веса у ConvNet + Compreno Net были инициализированы обученными моделями -
моделью показывающую 87.49\% для сверточной сети и моделью показывающую
72.85\% (см. таблицу \ref{table:union_net}) для второй нейронной сети.

\begin{table}[ht]
  \caption{Результаты с синтактико-семантическими признаками для объединенной нейросети}
  \centering
  \begin{tabulary}{\textwidth}{| L | L | L | L | L | L |}
    \hline\hline
    \multicolumn{1}{|p{1.5cm}|}{Модель} & Признаки & Выборка & Метод оптимизации & Полученная F1, \% \\
    \hline
    Compreno Net & Compreno sparse features & train & Mini-batch gradient descent & 72.85 \\
    \hline
    ConvNet & Embeddings, Capitalization, Position, Gazetteer & train & Mini-batch gradient descent & 87.49 \\
    \hline
    ConvNet + Compreno Net & Embeddings, Capitalization, Position, Gazetteer, Compreno sparse features & train & Mini-batch gradient descent & \textbf{88.47} \\
    \hline
    ConvNet + Compreno Net & Embeddings, Capitalization, Position, Gazetteer, Compreno sparse features & train + dev & Mini-batch gradient descent & 88.81 \\
    \hline
  \end{tabulary}
  \label{table:union_net}
\end{table}

По таблице \ref{table:union_net} видно, что признаки Compreno улучшают F1-меру почти на один процент.
