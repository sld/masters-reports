\chapter{Обзор литературы}

Победители соревнования по NER CoNLL 2003 \citep{florian2003named}, получившие 88.76\% F1,
представили систему использующую комбинацию различных алгоритмов машинного обучения.
В качестве признаков был использован их собственный, вручную составленный газетир,
POS-теги, CHUNK-теги, суффиксы, префиксы и выход других NER-классификаторов,
тренированных на внешних данных.

\citep{collobert2011natural} представили комбинацию сверточной нейронной сети
с условными случайными полями, получившую 89.59\% F1 на корпусе CoNLL 2003.
Их нейросетевая архитектура не зависит от задачи и используется как для NER, так и для
частеречной разметки (part-of-speech tagging), поиска синтаксически связанных групп
соседних слов (chunking), установления семантических ролей (semantic role labelling).
Для задачи NER они использовали три типа признаков - векторное представление слова,
капитализацию и небольшой газетир, включенный в соревнование CoNLL 2003.

\citep{chiu2015named} представили комбинацию сверточных сетей, рекуррентных сетей
и условных случайных полей.
Они использовали такие же признаки как у \citep{collobert2011natural}, дополнительный, вручную сформированный
газетир на основе DBpedia и обучались на
train+dev\footnote{Объединенная обучающая и валидационная выборки} выборке CoNLL 2003.
У них получилось 91.62\% F1. Кроме корпуса CoNLL 2003 они тестировали архитектуру
на более крупном англоязычном корпусе OntoNotes 5.0. На нем они получили
state-of-the-art результат 86.28\%.

\citep{DBLP:journals/corr/YangSC16} представили глубокую иерархическую рекуррентную нейросетевую
архитектуру с условными случайными полями для разметки последовательностей.
Они использовали такие же признаки как у \citep{collobert2011natural}.
Кроме англоязычного корпуса CoNLL 2003, где они получили state-of-the-art 90.94\% F1 при обучении
только на обучающей выборке (train set), они тестировали работу нейросети на CoNLL 2002 Dutch NER и CoNLL 2003 Spanish NER.
На этих корпусах они улучшили предыдущий state-of-the-art результат:
82.82\% до 85.19\% на CoNLL 2002 Dutch NER и 85.75\% до 85.77\% на CoNLL 2003 Spanish NER.

Современные работы используют векторное представление слов
и условные случайные поля в своих моделях. Из сторонних признаков применяют
только газетиры. В работах \citep{xu2014rc, bian2014knowledge} описано применение дополнительных признаков для
слов (морфологических, синтаксических, семантических) для создания более
совершенных векторных представлений.
Такие векторные представления помогают повысить оценку качества в
прикладных задачах \citep{xu2014rc}.
